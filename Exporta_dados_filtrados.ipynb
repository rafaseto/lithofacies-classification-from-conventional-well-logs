{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Autor: Átila"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U7lTIXdWUskc"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Álgebra linear\n",
        "import pandas as pd # Processamento de dados\n",
        "# import seaborn as sns # Visualização de dados\n",
        "import matplotlib.pyplot as plt # Visualização de dados\n",
        "from sklearn.preprocessing import StandardScaler # Normalização dos dados\n",
        "from sklearn.preprocessing import OneHotEncoder # Codificação de atributos categóricos\n",
        "from copy import deepcopy # Copiar objetos\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "58kB-FzUU2DA"
      },
      "outputs": [],
      "source": [
        "nomes_pocos = ['merged_1-BRSA-551-SE', 'merged_1-BRSA-574-SE', 'merged_1-BRSA-595-SE', 'merged_1-BRSA-605-SE', 'merged_1-BRSA-659-SE',\n",
        "              'merged_1-BRSA-689-SE', 'merged_1-BRSA-696-SE', 'merged_1-BRSA-698-SE']\n",
        "\n",
        "# Criação de um dicionário para armazenar os DataFrames associados aos nomes dos poços\n",
        "dfs_por_poco = {}\n",
        "\n",
        "for poco in glob.glob(r'**/Dados-fusao' + \"/*.csv\", recursive=True):\n",
        "    # Leitura do poço e armazenamento no dicionário\n",
        "    df = pd.read_csv(f'{poco}')\n",
        "    parts = poco.split(\"-\")\n",
        "    dfs_por_poco[f\"P_{parts[len(parts)-2]}\"] = df\n",
        "\n",
        "# Simplifica os nomes dos poços\n",
        "for idx, poco in enumerate(nomes_pocos):\n",
        "  parts = poco.split(\"-\")\n",
        "  nomes_pocos[idx] = f\"P_{parts[len(parts)-2]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JVEJBX1XU8Qt"
      },
      "outputs": [],
      "source": [
        "for poco in nomes_pocos:\n",
        "    # Seleciona apenas as colunas especificadas para o DataFrame\n",
        "    dfs_por_poco[poco] = dfs_por_poco[poco][['Poço', 'Profundidade', 'UnidadeF', 'UnidadeM', 'Litologia', 'BS', 'CAL', 'DCAL', 'GR', 'RESD', 'DT', 'RHOB',\n",
        "                                             'DRHO', 'NPHI', 'PE']].copy()\n",
        "\n",
        "    # Calcular o log na base 10 dos valores da coluna 'RESD'\n",
        "    dfs_por_poco[poco].loc[:, 'Log10_RESD'] = np.log10(dfs_por_poco[poco]['RESD'])\n",
        "\n",
        "    # Reordenar as colunas para que 'Log10 RESD' esteja imediatamente após 'RESD'\n",
        "    cols = dfs_por_poco[poco].columns.tolist()\n",
        "    resd_index = cols.index('RESD')\n",
        "    cols.insert(resd_index + 1, cols.pop(cols.index('Log10_RESD')))\n",
        "    dfs_por_poco[poco] = dfs_por_poco[poco][cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6nHjMDClVFe8"
      },
      "outputs": [],
      "source": [
        "# Aplicação dos filtros\n",
        "\n",
        "def filtra_coluna(df, coluna, min=None, max=None):\n",
        "    indices_para_remover = []\n",
        "    for index, row in df.iterrows():\n",
        "        if (min is not None and row[coluna] <= min) or (max is not None and row[coluna] >= max):\n",
        "            indices_para_remover.append(index)\n",
        "\n",
        "    df.drop(index=indices_para_remover, inplace=True)\n",
        "    return df\n",
        "\n",
        "colunas = ['GR', 'NPHI', 'RHOB', 'DRHO', 'RESD', 'DCAL', 'PE', 'Litologia']\n",
        "for poco in nomes_pocos:\n",
        "    #print(f\"{poco}:\")\n",
        "    #print(f\"Número de amostra antes do filtro de nulos: {len(dfs_por_poco[poco])}\")\n",
        "\n",
        "    # Excluir as linhas que não possuem alguma curva de perfil\n",
        "    dfs_por_poco[poco].dropna(subset=colunas, inplace=True)\n",
        "    #print(f\"Número de amostras depois do filtro de nulos: {len(dfs_por_poco[poco])}\")\n",
        "\n",
        "    # Aplica os filtros de perfis definidos pelos geólogos\n",
        "    dfs_por_poco[poco] = filtra_coluna(dfs_por_poco[poco], 'DCAL', max=1.5, min=-1)\n",
        "    dfs_por_poco[poco] = filtra_coluna(dfs_por_poco[poco], 'DRHO', min=-0.15, max=0.15)\n",
        "    #print(f\"Número de amostras depois do filtro de valores máximos e mínimos: {len(dfs_por_poco[poco])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "54aHXGBfV93e"
      },
      "outputs": [],
      "source": [
        "csv_directory = 'Dados-filtrados/'\n",
        "\n",
        "for poco in nomes_pocos:\n",
        "    # Salvar o DataFrame como um arquivo CSV\n",
        "    dfs_por_poco[poco].to_csv(f\"{csv_directory}/{poco}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
